// Module included in the following assemblies:
//
// * nodes/nodes-pods-autoscaling-about.adoc

:_content-type: CONCEPT
[id="nodes-clusters-autoscaling-horizontal_{context}"]
= Understanding horizontal pod autoscalers

You can create a horizontal pod autoscaler to specify the minimum and maximum number of pods
you want to run, as well as the CPU utilization or memory utilization your pods should target.

The autoscaler works as a control loop with a default of 15 seconds for the sync period. During this period, the controller manager queries the CPU, memory utilization, or both, against what is defined in the YAML file for the HPA.
The controller manager obtains the utilization metrics from the resource metrics API for per-pod resource metrics like CPU or memory, for each pod that is targeted by the HPA.

If a utilization value target is set, the controller calculates the utilization value as a percentage of the equivalent resource request on the containers in each pod. The controller then takes the average of utilization across all targeted pods and produces a ratio that is used to scale the number of desired replicas.
The HPA is configured to fetch metrics from `metrics.k8s.io`, which is provided by the metrics server. Because of the dynamic nature of metrics evaluation, the number of replicas can fluctuate during scaling for a group of replicas.

For replication controllers, this scaling corresponds directly to the replicas
of the replication controller. For deployment configurations, scaling corresponds
directly to the replica count of the deployment configuration. Note that autoscaling
applies only to the latest deployment in the `Complete` phase.

{product-title} automatically accounts for resources and prevents unnecessary autoscaling
during resource spikes, such as during start up. Pods in the `unready` state
have `0 CPU` usage when scaling up and the autoscaler ignores the pods when scaling down.
Pods without known metrics have `0% CPU` usage when scaling up and `100% CPU` when scaling down.
This allows for more stability during the HPA decision. To use this feature, you must configure
readiness checks to determine if a new pod is ready for use.

ifdef::openshift-origin,openshift-enterprise,openshift-webscale[]
To use horizontal pod autoscalers, your cluster administrator must have
properly configured cluster metrics.
endif::openshift-origin,openshift-enterprise,openshift-webscale[]

== Supported metrics

The following metrics are supported by horizontal pod autoscalers:

.Metrics
[cols="3a,5a,5a",options="header"]
|===

|Metric |Description |API version

|CPU utilization
|Number of CPU cores used. Can be used to calculate a percentage of the pod's requested CPU.
|`autoscaling/v1`, `autoscaling/v2beta2`

|Memory utilization
|Amount of memory used. Can be used to calculate a percentage of the pod's requested memory.
|`autoscaling/v2beta2`
|===

The scheduler uses the resource request that you specify for containers in a pod, to decide which node to place the pod on. The kubelet enforces the resource limit that you specify for a container to ensure that the container is not allowed to use more than the specified limit.
The kubelet also reserves the request amount of that system resource specifically for that container to use.

In the pod specifications, you must specify the resource requests, such as CPU and memory. The HPA uses this specification to determine the resource utilization and then scales the target up or down.

For example, the HPA object uses the following metric source:

[source,yaml]
----
type: Resource
resource:
  name: cpu
  target:
    type: Utilization
    averageUtilization: 60
----

In this example, the HPA keeps the average utilization of the pods in the scaling target at 60%. Utilization is the ratio between the current resource usage to the requested resource of the pod.

[IMPORTANT]
====
For memory-based autoscaling, memory usage must increase and decrease
proportionally to the replica count. On average:

* An increase in replica count must lead to an overall decrease in memory
(working set) usage per-pod.
* A decrease in replica count must lead to an overall increase in per-pod memory
usage.

Use the {product-title} web console to check the memory behavior of your application
and ensure that your application meets these requirements before using
memory-based autoscaling.
====

The following example shows autoscaling for the `image-registry` `Deployment` object. The initial deployment requires 3 pods. The HPA object increases the minimum to 5. If CPU usage on the pods reaches 75%, the pods increase to 7:

[source,terminal]
----
$ oc autoscale deployment/image-registry --min=5 --max=7 --cpu-percent=75
----

.Example output
[source,terminal]
----
horizontalpodautoscaler.autoscaling/image-registry autoscaled
----

.Sample HPA for the `image-registry` `Deployment` object with `minReplicas` set to 3
[source,yaml]
----
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: image-registry
  namespace: default
spec:
  maxReplicas: 7
  minReplicas: 3
  scaleTargetRef:
    apiVersion: apps.openshift.io/v1
    kind: Deployment
    name: image-registry
  targetCPUUtilizationPercentage: 75
status:
  currentReplicas: 5
  desiredReplicas: 0
----

. View the new state of the deployment:
+
[source,terminal]
----
$ oc get deployment image-registry
----
+
There are now 5 pods in the deployment:
+
.Example output
[source,terminal]
----
NAME             REVISION   DESIRED   CURRENT   TRIGGERED BY
image-registry   1          5         5         config
----
