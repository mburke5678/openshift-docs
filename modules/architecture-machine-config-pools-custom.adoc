// Module included in the following assemblies:
//
// * architecture/control-plane.adoc

[id="architecture-machine-config-pools-custom_{context}"]
= Configuring a node by using custom machine config pools

You can create custom machine config pools that give you the ability to deploy changes that are targeted at specific nodes. One example of this is an infrastructure node that hosts only infrastructure components, such as the router and image registry.   

For information on infra nodes, see the Additional resources at the end of this section.

Custom machine config pools are based on the worker machine config pool. As such, custom pools inherit their initial configuration from the worker pool and any change to the worker pool is applied to the custom pool. Changes to the custom pool are not inherited by the worker pool.

[NOTE]
====
You cannot use a master machine config pool to create a custom pool.
====

Note the following about nodes and machine config pools:

* A node can only be included in one machine config pool. 
* A node must be included in a machine config pool for the node to function properly.
* If a node has multiple labels that correspond to different pools, such as `worker,infra`, the node is managed by the custom pool, not the worker pool. Custom pools take priority on selecting nodes to manage based on node labels.
* If a node has the `worker,infra` label, but you do not have an infra machine config pool, the Machine Config Operator (MCO) considers the node a worker node.
* If a node has only a custom label that does not have a corresponding custom pool, the node is not recognized by the MCO and is unmanaged by the cluster.

Because the custom pool inherits its configuration from the worker machine config pool by default, a purely custom node stills get updated when a worker machine config is updated. However, workloads scheduled for worker nodes are no longer scheduled on the custom node.

[NOTE]
====
If a custom node reboots, the node reboots into the `worker` machine config pool. You need to reapply the custom label to that node to place the node in the custom pool. 
====

To add a node to a custom machine config pool, first add a custom role label to the node, for example: `infra`:

[source,terminal]
----
$ oc label node ip-10-0-130-218.us-west-1.compute.internal node-role.kubernetes.io/infra=
----

The `oc get nodes` output shows that node with the `worker` and custom roles.

.Example output
[source,terminal]
----
NAME                                         STATUS    ROLES          AGE   VERSION
ip-10-0-130-218.us-west-1.compute.internal   Ready     infra,worker   37m   v1.14.0+e020ea5b3
ip-10-0-131-9.us-west-1.compute.internal     Ready     master         43m   v1.14.0+e020ea5b3
ip-10-0-134-237.us-west-1.compute.internal   Ready     master         43m   v1.14.0+e020ea5b3
ip-10-0-138-167.us-west-1.compute.internal   Ready     worker         37m   v1.14.0+e020ea5b3
ip-10-0-151-146.us-west-1.compute.internal   Ready     master         43m   v1.14.0+e020ea5b3
ip-10-0-152-59.us-west-1.compute.internal    Ready     worker         37m   v1.14.0+e020ea5b3
----

If you want to use the node with only the custom role, remove the worker pool, for example:

[source,terminal]
----
$ oc label node ip-10-0-130-218.us-west-1.compute.internal node-role.kubernetes.io/worker-
----

After you add the custom role label, create a machine config pool that contains the custom role as the `machineConfigSelector`. 

[source,yaml]
----
apiVersion: machineconfiguration.openshift.io/v1
kind: MachineConfigPool
metadata:
  name: infra
spec:
  machineConfigSelector:
    matchExpressions:
      - {key: machineconfiguration.openshift.io/role, operator: In, values: [worker,infra]} <1>
  nodeSelector:
    matchLabels:
      node-role.kubernetes.io/infra: ""
----
<1> You must include `worker` as a value, even if you removed the `worker` label from your custom node.

The `oc get mcp` output shows the new machine config pool:

.Example output
[source,terminal]
----
NAME     CONFIG                                             UPDATED   UPDATING   DEGRADED   MACHINECOUNT   READYMACHINECOUNT   UPDATEDMACHINECOUNT   DEGRADEDMACHINECOUNT   AGE
custom                                                      False     True       False      1              0                   0                     0                      15s
master   rendered-master-b1d4b6196a18869d63518e57b8b335d1   True      False      False      3              3                   3                     0                      156m
worker   rendered-worker-c48ef626ff01f0a445979a4245dc7bdd   True      False      False      3              3                   3                     0                      156m
----

To deploy changes to a custom pool, create a machine config that uses the custom pool as the label, for example:

[source,yaml]
----
apiVersion: machineconfiguration.openshift.io/v1
kind: MachineConfig
metadata:
  labels:
    machineconfiguration.openshift.io/role: infra
  name: 51-infra
spec:
  config:
    ignition:
      version: {ign-config-version}
    storage:
      files:
      - contents:
          source: data:,infra
        filesystem: root
        mode: 0644
        path: /etc/infratest
----

After a node returns to the `Ready` state, you can see that the machine config pool has been applied:

[source,terminal]
----
$ oc get mcp
----

.Example output
[source,terminal]
----
NAME     CONFIG                                             UPDATED   UPDATING   DEGRADED   MACHINECOUNT   READYMACHINECOUNT   UPDATEDMACHINECOUNT   DEGRADEDMACHINECOUNT   AGE
infra    rendered-custom-11f6e3ee8704373add6d3c3d8399b3fa   True      False      False      1              1                   1                     0                      11m
master   rendered-master-94cafd2f05c7cd9a3fce4877e699fa45   True      False      False      3              3                   3                     0                      119m
worker   rendered-worker-93ac02b5fc2e2526b8b15758df3d8472   True      False      False      2              2                   2                     0                      119m
----

Now, if you make a change to the `worker` machine config, the change is applied to the `worker` and custom machine config pools and their associated nodes. 

.Example output
[source,terminal]
----
NAME     CONFIG                                             UPDATED   UPDATING   DEGRADED   MACHINECOUNT   READYMACHINECOUNT   UPDATEDMACHINECOUNT   DEGRADEDMACHINECOUNT   AGE
infra    rendered-custom-e7c94136ebb9f655bb20d7da14eb6c1f   False     True       False      1              0                   0                     0                      74m
master   rendered-master-6e3f6a6544848b5e1d8fccf57283263d   True      False      False      3              3                   3                     0                      113m
worker   rendered-worker-0a1b442474e43fee1d60a4b9aeb79ca0   False     True       False      2              0                   0                     0                      113m
mburke@mburke ~ $ oc get nodes
----

Changes made to the custom machine config are not applied to the `worker` machine config.

You can remove a node from a custom machine config pool by removing the label from the custom node. Because each node must have a role at all times to properly function. If you have a purely custom node, you should first apply a worker role label to the node before you remove the custom role label.

[source,terminal]
----
$ oc label node ip-10-0-130-218.us-west-1.compute.internal node-role.kubernetes.io/worker=
----

[source,terminal]
----
$ oc label node ip-10-0-130-218.us-west-1.compute.internal node-role.kubernetes.io/infra-
----

You can see the node was removed from the custom machine config pool and returned to the `worker` config pool.

.Example output
[source,terminal]
----
NAME     CONFIG                                             UPDATED   UPDATING   DEGRADED   MACHINECOUNT   READYMACHINECOUNT   UPDATEDMACHINECOUNT   DEGRADEDMACHINECOUNT   AGE
custom   rendered-custom-11f6e3ee8704373add6d3c3d8399b3fa   True      False      False      0              0                   0                     0                      18m
master   rendered-master-94cafd2f05c7cd9a3fce4877e699fa45   True      False      False      3              3                   3                     0                      125m
worker   rendered-worker-93ac02b5fc2e2526b8b15758df3d8472   False     True       False      3              3                   3                     0                      125m
----
